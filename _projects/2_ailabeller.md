---
title: Data Labeller
slug: ailabeller
display: true
WIP: false

project-title: Streamlining AI development workflows.
company-name: Element AI
company-link: https://www.servicenow.com/
company-industry: AI
company-type: B2B
application-type: Web Application
my-impact: UX design
thumbnail-path: /assets/2_ailabeller/ailabeller_thumb.png
thumbnail-alt: Screenshot of Data Labeller application, a web application that manages AI labelling tasks.

layout: wide-project
---

### Project

I worked on an AI model development product, which was a product formed from several internal tools created by AI developers at Element AI to streamline internal workflows. The technical back-end was state-of-the-art, but lacked a front-end or cohesive user experience, relying solely on documentation for user guidance.

In particular, I focused on the data labelling tool, which facilitated collaboration between AI practitioners and data labellers during the labelling process. My role was the sole product designer, working with a front- and back-end dev, a product owner, and a UX researcher.

### Objective

Starting a simple labelling task involved navigating a fragmented workflow across the command-line, JIRA, Slack, and two separate dashboards. The main goal was to transform the disjointed experience into a cohesive and guided flow.

### Work

I conducted in-context observations and desk research on the existing cross-platform task creation process. I paired these with high-level user flows that were the outputs of a design sprint run by my colleagues.

![A diagram of a scattered labelling workflow and a photo of a man working at a desk in an office.](/assets/2_ailabeller/labeller_workflow.png "Existing workflow of AI Labeller being observed in context.")

Using these inputs, I delivered revised user flows and rough prototypes of the task creation process. I validated the technical feasibility of the proposed prototypes with the front- and back-end developers.

![A rough low-fidelity prototype of AI Labeller.](/assets/2_ailabeller/labeller_low fi.png "Low-fidelity Comic Sans mockups of AI Labeller.")

I worked with the product owner and a UX researcher to identify what we wanted to focus on in user interviews, focusing on new concepts and flows that needed user validation.

Based on interview insights, I refined the high-fidelity prototypes, which were then implemented by the developers.

![A high-fidelity prototype of AI Labeller dashboard.](/assets/2_ailabeller/labeller_dashboard.png "A high-fidelity prototype of AI Labeller dashboard.")

### End result

The resulting task creation process was much easier to use and learn, and eliminated the need to jump between platforms just to initiate a task. This also made the product significantly more appealing in sales demos.

![A high-fidelity prototype of AI Labeller create task screen.](/assets/2_ailabeller/labeller_create task 1.png "A high-fidelity prototype of AI Labeller create task screen.")

![A high-fidelity prototype of AI Labeller create task screen.](/assets/2_ailabeller/labeller_create task 2.png "A high-fidelity prototype of AI Labeller create task screen.")

### Reflection

During this process, I learned where to build on existing design patterns that had already proven to be effective: for example, AI practitioners frequently needed to attach instructions to their labelling tasks, which often came as a Google Doc. We spent a few iterations trying to flesh out the rich text editing capabilities of our text field before deciding based on testing to simplify it into a field for pasting a Google Doc link, which fit in better with their existing workflow.

I learned to spot and challenge my assumptions about user thinking, and I also learned the value in testing at multiple levels, using both high-fidelity mockups to test usability, and abstract concepts to challenge broader workflow assumptions.
